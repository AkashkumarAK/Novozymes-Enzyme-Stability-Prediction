{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T02:57:13.221495Z",
     "iopub.status.busy": "2022-11-03T02:57:13.221075Z",
     "iopub.status.idle": "2022-11-03T02:57:24.204002Z",
     "shell.execute_reply": "2022-11-03T02:57:24.202306Z",
     "shell.execute_reply.started": "2022-11-03T02:57:13.221459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ystan (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mcv (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ystan (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mcv (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting gensim==4.1.2\n",
      "  Downloading gensim-4.1.2.tar.gz (23.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gensim==4.1.2) (1.22.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gensim==4.1.2) (1.8.1)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gensim==4.1.2) (5.2.1)\n",
      "Building wheels for collected packages: gensim\n",
      "  Building wheel for gensim (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gensim: filename=gensim-4.1.2-cp310-cp310-macosx_10_9_universal2.whl size=24425947 sha256=88ef20229b2aa56cacb24c354222a710a3b6428048506a80073a3f67c353b3c2\n",
      "  Stored in directory: /Users/prkskrs/Library/Caches/pip/wheels/4f/4e/73/8b69e5f901197006f4cfaadbb4926c707d5acee8b87e70b55f\n",
      "Successfully built gensim\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ystan (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mcv (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ystan (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution -mcv (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: gensim 4.2.0\n",
      "    Uninstalling gensim-4.2.0:\n",
      "      Successfully uninstalled gensim-4.2.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ystan (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mcv (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed gensim-4.1.2\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ystan (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mcv (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ystan (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mcv (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ystan (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -mcv (/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gensim==4.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-03T02:57:24.206854Z",
     "iopub.status.busy": "2022-11-03T02:57:24.206491Z",
     "iopub.status.idle": "2022-11-03T02:57:24.216499Z",
     "shell.execute_reply": "2022-11-03T02:57:24.215194Z",
     "shell.execute_reply.started": "2022-11-03T02:57:24.206822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/novozymes-enzyme-stability-prediction/sample_submission.csv\n",
      "/kaggle/input/novozymes-enzyme-stability-prediction/wildtype_structure_prediction_af2.pdb\n",
      "/kaggle/input/novozymes-enzyme-stability-prediction/train.csv\n",
      "/kaggle/input/novozymes-enzyme-stability-prediction/test.csv\n",
      "/kaggle/input/novozymes-enzyme-stability-prediction/train_updates_20220929.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T02:57:29.980025Z",
     "iopub.status.busy": "2022-11-03T02:57:29.978987Z",
     "iopub.status.idle": "2022-11-03T02:57:32.701438Z",
     "shell.execute_reply": "2022-11-03T02:57:32.700292Z",
     "shell.execute_reply.started": "2022-11-03T02:57:29.979985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "      <th>data_source</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAAAKAAALALLGEAPEVVDIWLPAGWRQPFRVFRLERKGDGVLVG...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>75.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AAADGEPLHNEEERAGAGQVGRSLPQESEEQRTGSRPRRRRDLGSR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>50.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AAAFSTPRATSYRILSSAGSGSTRADAPQVRRLHTTRDLLAKDYYA...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AAASGLRTAIPAQPLRHLLQPAPRPCLRPFGLLSVRAGSARRSGLL...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>47.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AAATKSGPRRQSQGASVRTFTPFYFLVEPVDTLSVRGSSVILNCSA...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>49.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28976</th>\n",
       "      <td>31385</td>\n",
       "      <td>YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>51.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28977</th>\n",
       "      <td>31386</td>\n",
       "      <td>YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28978</th>\n",
       "      <td>31387</td>\n",
       "      <td>YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28979</th>\n",
       "      <td>31388</td>\n",
       "      <td>YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28980</th>\n",
       "      <td>31389</td>\n",
       "      <td>YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
       "      <td>37.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28981 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seq_id                                   protein_sequence   pH  \\\n",
       "0           0  AAAAKAAALALLGEAPEVVDIWLPAGWRQPFRVFRLERKGDGVLVG...  7.0   \n",
       "1           1  AAADGEPLHNEEERAGAGQVGRSLPQESEEQRTGSRPRRRRDLGSR...  7.0   \n",
       "2           2  AAAFSTPRATSYRILSSAGSGSTRADAPQVRRLHTTRDLLAKDYYA...  7.0   \n",
       "3           3  AAASGLRTAIPAQPLRHLLQPAPRPCLRPFGLLSVRAGSARRSGLL...  7.0   \n",
       "4           4  AAATKSGPRRQSQGASVRTFTPFYFLVEPVDTLSVRGSSVILNCSA...  7.0   \n",
       "...       ...                                                ...  ...   \n",
       "28976   31385  YYMYSGGGSALAAGGGGAGRKGDWNDIDSIKKKDLHHSRGDEKAQG...  7.0   \n",
       "28977   31386  YYNDQHRLSSYSVETAMFLSWERAIVKPGAMFKKAVIGFNCNVDLI...  7.0   \n",
       "28978   31387  YYQRTLGAELLYKISFGEMPKSAQDSAENCPSGMQFPDTAIAHANV...  7.0   \n",
       "28979   31388  YYSFSDNITTVFLSRQAIDDDHSLSLGTISDVVESENGVVAADDAR...  7.0   \n",
       "28980   31389  YYVPDEYWQSLEVAHKLTFGYGYLTWEWVQGIRSYVYPLLIAGLYK...  7.0   \n",
       "\n",
       "                             data_source    tm  \n",
       "0      doi.org/10.1038/s41592-020-0801-4  75.7  \n",
       "1      doi.org/10.1038/s41592-020-0801-4  50.5  \n",
       "2      doi.org/10.1038/s41592-020-0801-4  40.5  \n",
       "3      doi.org/10.1038/s41592-020-0801-4  47.2  \n",
       "4      doi.org/10.1038/s41592-020-0801-4  49.5  \n",
       "...                                  ...   ...  \n",
       "28976  doi.org/10.1038/s41592-020-0801-4  51.8  \n",
       "28977  doi.org/10.1038/s41592-020-0801-4  37.2  \n",
       "28978  doi.org/10.1038/s41592-020-0801-4  64.6  \n",
       "28979  doi.org/10.1038/s41592-020-0801-4  50.7  \n",
       "28980  doi.org/10.1038/s41592-020-0801-4  37.6  \n",
       "\n",
       "[28981 rows x 5 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Will take 3-5 seconds to run\n",
    "def load_fixed_train_df(original_train_file_path=\"/kaggle/input/novozymes-enzyme-stability-prediction/train.csv\",\n",
    "                        update_file_path=\"/kaggle/input/novozymes-enzyme-stability-prediction/train_updates_20220929.csv\",\n",
    "                        was_fixed_col=False):\n",
    "    def _fix_tm_ph(_row, update_map):\n",
    "        update_vals = update_map.get(_row[\"seq_id\"], None)\n",
    "        if update_vals is not None:\n",
    "            _row[\"tm\"] = update_vals[\"tm\"]\n",
    "            _row[\"pH\"] = update_vals[\"pH\"]\n",
    "        return _row\n",
    "\n",
    "    # Load dataframes\n",
    "    _df = pd.read_csv(original_train_file_path)\n",
    "    _updates_df = pd.read_csv(update_file_path)\n",
    "\n",
    "    # Identify which sequence ids need to have the tm and pH values changed and create a dictionary mapping \n",
    "    seqid_2_phtm_update_map = _updates_df[~pd.isna(_updates_df[\"pH\"])].groupby(\"seq_id\")[[\"pH\", \"tm\"]].first().to_dict(\"index\")\n",
    "\n",
    "    # Identify the sequence ids that will be dropped due to data quality issues\n",
    "    bad_seqids = _updates_df[pd.isna(_updates_df[\"pH\"])][\"seq_id\"].to_list()\n",
    "\n",
    "    # Fix bad sequence ids\n",
    "    _df = _df[~_df[\"seq_id\"].isin(bad_seqids)].reset_index(drop=True)\n",
    "\n",
    "    # Fix pH and tm swaparoo\n",
    "    _df = _df.apply(lambda x: _fix_tm_ph(x, seqid_2_phtm_update_map), axis=1)\n",
    "\n",
    "    # Add in a bool to track if a row was fixed or not (tm/ph swap will look the same as bad data)\n",
    "    if was_fixed_col: _df[\"was_fixed\"] = _df[\"seq_id\"].isin(bad_seqids+list(seqid_2_phtm_update_map.keys()))\n",
    "\n",
    "    return _df\n",
    "\n",
    "\n",
    "protein_dataset = load_fixed_train_df()\n",
    "protein_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T02:57:35.881156Z",
     "iopub.status.busy": "2022-11-03T02:57:35.880781Z",
     "iopub.status.idle": "2022-11-03T02:57:35.897057Z",
     "shell.execute_reply": "2022-11-03T02:57:35.896265Z",
     "shell.execute_reply.started": "2022-11-03T02:57:35.881127Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feature_columns = [\"protein_sequence\", \"pH\"]\n",
    "target_columns = \"tm\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(protein_dataset[feature_columns], protein_dataset[target_columns], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T02:57:38.368864Z",
     "iopub.status.busy": "2022-11-03T02:57:38.368130Z",
     "iopub.status.idle": "2022-11-03T02:57:38.374136Z",
     "shell.execute_reply": "2022-11-03T02:57:38.373294Z",
     "shell.execute_reply.started": "2022-11-03T02:57:38.368826Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "\n",
    "class MyDataset:\n",
    "    # creatign a wrapper to process a sentence\n",
    "    def __iter__(self):\n",
    "        for line in X_train['protein_sequence'].values.tolist():\n",
    "            yield [*line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T02:57:40.612444Z",
     "iopub.status.busy": "2022-11-03T02:57:40.611412Z",
     "iopub.status.idle": "2022-11-03T02:57:40.617893Z",
     "shell.execute_reply": "2022-11-03T02:57:40.616684Z",
     "shell.execute_reply.started": "2022-11-03T02:57:40.612407Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T02:57:43.660492Z",
     "iopub.status.busy": "2022-11-03T02:57:43.660074Z",
     "iopub.status.idle": "2022-11-03T02:58:30.040080Z",
     "shell.execute_reply": "2022-11-03T02:58:30.039233Z",
     "shell.execute_reply.started": "2022-11-03T02:57:43.660452Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "protein_seqs = MyDataset()\n",
    "# training word2vec for our own dataset\n",
    "model = gensim.models.Word2Vec(sentences=protein_seqs, min_count=10, vector_size=20, window=11, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T03:03:16.142872Z",
     "iopub.status.busy": "2022-11-03T03:03:16.142439Z",
     "iopub.status.idle": "2022-11-03T03:03:16.159497Z",
     "shell.execute_reply": "2022-11-03T03:03:16.158183Z",
     "shell.execute_reply.started": "2022-11-03T03:03:16.142827Z"
    }
   },
   "outputs": [],
   "source": [
    "def tsnescatterplot(model, word, list_names):\n",
    "    \"\"\" Plot in seaborn the results from the t-SNE dimensionality reduction algorithm of the vectors of a query word,\n",
    "    its list of most similar words, and a list of words.\n",
    "    \"\"\"\n",
    "    arrays = np.empty((0, 20), dtype='f')\n",
    "    word_labels = [word]\n",
    "    color_list  = ['red']\n",
    "\n",
    "    # adds the vector of the query word\n",
    "    arrays = np.append(arrays, model.wv.__getitem__([word]), axis=0)\n",
    "    \n",
    "    # gets list of most similar words\n",
    "    close_words = model.wv.most_similar([word])\n",
    "    \n",
    "    # adds the vector for each of the closest words to the array\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model.wv.__getitem__([wrd_score[0]])\n",
    "        word_labels.append(wrd_score[0])\n",
    "        color_list.append('blue')\n",
    "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
    "    \n",
    "    # adds the vector for each of the words from list_names to the array\n",
    "    for wrd in list_names:\n",
    "        wrd_vector = model.wv.__getitem__([wrd])\n",
    "        word_labels.append(wrd)\n",
    "        color_list.append('green')\n",
    "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
    "        \n",
    "    # Reduces the dimensionality from 300 to 50 dimensions with PCA\n",
    "    reduc = PCA(n_components=20).fit_transform(arrays)\n",
    "    \n",
    "    # Finds t-SNE coordinates for 2 dimensions\n",
    "    np.set_printoptions(suppress=True)\n",
    "    \n",
    "    Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(reduc)\n",
    "    \n",
    "    # Sets everything up to plot\n",
    "    df = pd.DataFrame({'x': [x for x in Y[:, 0]],\n",
    "                       'y': [y for y in Y[:, 1]],\n",
    "                       'words': word_labels,\n",
    "                       'color': color_list})\n",
    "    \n",
    "    fig, _ = plt.subplots()\n",
    "    fig.set_size_inches(9, 9)\n",
    "    \n",
    "    # Basic plot\n",
    "    p1 = sns.regplot(data=df,\n",
    "                     x=\"x\",\n",
    "                     y=\"y\",\n",
    "                     fit_reg=False,\n",
    "                     marker=\"o\",\n",
    "                     scatter_kws={'s': 40,\n",
    "                                  'facecolors': df['color']\n",
    "                                 }\n",
    "                    )\n",
    "    \n",
    "    # Adds annotations one by one with a loop\n",
    "    for line in range(0, df.shape[0]):\n",
    "         p1.text(df[\"x\"][line],\n",
    "                 df['y'][line],\n",
    "                 '  ' + df[\"words\"][line].title(),\n",
    "                 horizontalalignment='left',\n",
    "                 verticalalignment='bottom', size='medium',\n",
    "                 color=df['color'][line],\n",
    "                 weight='normal'\n",
    "                ).set_size(15)\n",
    "\n",
    "    \n",
    "    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n",
    "    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n",
    "            \n",
    "    plt.title('t-SNE visualization for Acid {}'.format(word.title()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T03:04:46.319784Z",
     "iopub.status.busy": "2022-11-03T03:04:46.319393Z",
     "iopub.status.idle": "2022-11-03T03:04:46.763259Z",
     "shell.execute_reply": "2022-11-03T03:04:46.761968Z",
     "shell.execute_reply.started": "2022-11-03T03:04:46.319737Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsnescatterplot(model, 'G',[t[0] for t in model.wv.most_similar(positive=[\"G\"], topn=20)][10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T03:08:06.325145Z",
     "iopub.status.busy": "2022-11-03T03:08:06.324732Z",
     "iopub.status.idle": "2022-11-03T03:08:06.332427Z",
     "shell.execute_reply": "2022-11-03T03:08:06.331312Z",
     "shell.execute_reply.started": "2022-11-03T03:08:06.325111Z"
    }
   },
   "outputs": [],
   "source": [
    "def getAverageVectors(sentence):\n",
    "    tokens = [*sentence] # split sentence to tokens on space\n",
    "    result = np.zeros(20) # start with zero result\n",
    "\n",
    "    for token in tokens:\n",
    "        # try except block helps in ignoring words that are not present in word2Vec model\n",
    "        try: \n",
    "            result = np.add(result, model.wv[token])\n",
    "        except:\n",
    "            pass\n",
    "    # find avgerage of the result\n",
    "    result = result / len(tokens)\n",
    "    return ','.join(map(str, result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T01:10:55.611758Z",
     "iopub.status.busy": "2022-11-03T01:10:55.610944Z",
     "iopub.status.idle": "2022-11-03T01:11:30.423040Z",
     "shell.execute_reply": "2022-11-03T01:11:30.421853Z",
     "shell.execute_reply.started": "2022-11-03T01:10:55.611727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_sequence</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16502</th>\n",
       "      <td>-0.01007100484737127,0.020716818481138568,-0.0...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>-0.0019297180877411893,0.02377931755653567,-0....</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731</th>\n",
       "      <td>0.0012389976143852243,0.007089151173850389,-0....</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8663</th>\n",
       "      <td>-0.0076030583364627095,0.009252273952006363,-0...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27605</th>\n",
       "      <td>-0.002767845586134885,0.022326212941911748,-0....</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18893</th>\n",
       "      <td>0.00464730405672805,0.03380839553079834,0.0005...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>-0.005680721333589066,0.017120178307999265,-0....</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>-0.010295576337912228,0.002239035001957661,-0....</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11756</th>\n",
       "      <td>-0.019038924893094084,0.0044116757211753125,0....</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23790</th>\n",
       "      <td>0.0055552497412068675,0.022527759612509697,-0....</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5797 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        protein_sequence   pH\n",
       "16502  -0.01007100484737127,0.020716818481138568,-0.0...  3.0\n",
       "843    -0.0019297180877411893,0.02377931755653567,-0....  7.0\n",
       "5731   0.0012389976143852243,0.007089151173850389,-0....  7.0\n",
       "8663   -0.0076030583364627095,0.009252273952006363,-0...  7.0\n",
       "27605  -0.002767845586134885,0.022326212941911748,-0....  7.0\n",
       "...                                                  ...  ...\n",
       "18893  0.00464730405672805,0.03380839553079834,0.0005...  7.0\n",
       "2698   -0.005680721333589066,0.017120178307999265,-0....  7.0\n",
       "4199   -0.010295576337912228,0.002239035001957661,-0....  7.0\n",
       "11756  -0.019038924893094084,0.0044116757211753125,0....  7.0\n",
       "23790  0.0055552497412068675,0.022527759612509697,-0....  5.5\n",
       "\n",
       "[5797 rows x 2 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_copy = X_train.copy()\n",
    "x_train_copy['protein_sequence'] = x_train_copy['protein_sequence'].apply(lambda x: getAverageVectors(x))\n",
    "x_train_copy\n",
    "\n",
    "x_test_copy = X_test.copy()\n",
    "x_test_copy['protein_sequence'] = x_test_copy['protein_sequence'].apply(lambda x: getAverageVectors(x))\n",
    "x_test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T01:11:30.424774Z",
     "iopub.status.busy": "2022-11-03T01:11:30.424471Z",
     "iopub.status.idle": "2022-11-03T01:11:30.599553Z",
     "shell.execute_reply": "2022-11-03T01:11:30.598442Z",
     "shell.execute_reply.started": "2022-11-03T01:11:30.424747Z"
    }
   },
   "outputs": [],
   "source": [
    "train = x_train_copy['protein_sequence'].str.split(',', -1, expand=True)\n",
    "test = x_test_copy['protein_sequence'].str.split(',', -1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T01:11:30.603669Z",
     "iopub.status.busy": "2022-11-03T01:11:30.603338Z",
     "iopub.status.idle": "2022-11-03T01:11:30.636242Z",
     "shell.execute_reply": "2022-11-03T01:11:30.635217Z",
     "shell.execute_reply.started": "2022-11-03T01:11:30.603639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>-0.00706682954747062</td>\n",
       "      <td>0.01996781248263679</td>\n",
       "      <td>-0.013601513556938886</td>\n",
       "      <td>-0.01077419164515025</td>\n",
       "      <td>0.034717422380397385</td>\n",
       "      <td>0.052683456591645104</td>\n",
       "      <td>-0.02132001722615363</td>\n",
       "      <td>0.025572076695761434</td>\n",
       "      <td>-0.0008094727317592851</td>\n",
       "      <td>0.007029286265343864</td>\n",
       "      <td>-0.07567065814090473</td>\n",
       "      <td>-0.05867228435804996</td>\n",
       "      <td>-0.08707858990512889</td>\n",
       "      <td>0.013089384874465313</td>\n",
       "      <td>-0.043677887445114354</td>\n",
       "      <td>-0.10073068651983196</td>\n",
       "      <td>0.282148170545026</td>\n",
       "      <td>-0.17623799561883682</td>\n",
       "      <td>-0.3917241754966813</td>\n",
       "      <td>0.4433238150568696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912</th>\n",
       "      <td>-0.0013864726187148054</td>\n",
       "      <td>0.02203218482619284</td>\n",
       "      <td>0.004126875728351459</td>\n",
       "      <td>-0.014449601574878759</td>\n",
       "      <td>0.02737126940350991</td>\n",
       "      <td>0.04360691650919097</td>\n",
       "      <td>-0.011711142661667</td>\n",
       "      <td>0.03003467550506994</td>\n",
       "      <td>0.015308702600998775</td>\n",
       "      <td>0.003992990647578156</td>\n",
       "      <td>-0.08925564643629934</td>\n",
       "      <td>-0.049872565095820366</td>\n",
       "      <td>-0.07808278877094918</td>\n",
       "      <td>0.014014008626177469</td>\n",
       "      <td>-0.04130462270580382</td>\n",
       "      <td>-0.10628305586060688</td>\n",
       "      <td>0.2773202256337039</td>\n",
       "      <td>-0.19328804736547517</td>\n",
       "      <td>-0.36903954899347974</td>\n",
       "      <td>0.45759566815644964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20717</th>\n",
       "      <td>0.008983750991099323</td>\n",
       "      <td>0.02368557540650229</td>\n",
       "      <td>0.00013234988294686157</td>\n",
       "      <td>-0.006080677074359924</td>\n",
       "      <td>0.040763485880758045</td>\n",
       "      <td>0.04409194367300137</td>\n",
       "      <td>-0.011764170012840455</td>\n",
       "      <td>0.026934225969106752</td>\n",
       "      <td>0.0189247682271187</td>\n",
       "      <td>0.008414136009633578</td>\n",
       "      <td>-0.09445401626136199</td>\n",
       "      <td>-0.04720036891025782</td>\n",
       "      <td>-0.07217291057263174</td>\n",
       "      <td>0.012880380718391524</td>\n",
       "      <td>-0.03792636959529403</td>\n",
       "      <td>-0.0924403506982846</td>\n",
       "      <td>0.27535202020450017</td>\n",
       "      <td>-0.17923264435016648</td>\n",
       "      <td>-0.36526467479747377</td>\n",
       "      <td>0.4648126223762734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10385</th>\n",
       "      <td>-0.014656537184149743</td>\n",
       "      <td>0.01842433754565184</td>\n",
       "      <td>-0.015861016172668396</td>\n",
       "      <td>-0.02357154274569814</td>\n",
       "      <td>0.03668313008591027</td>\n",
       "      <td>0.04792766738255472</td>\n",
       "      <td>-0.03691827117644335</td>\n",
       "      <td>0.015225870158565415</td>\n",
       "      <td>-0.0018293998930287564</td>\n",
       "      <td>0.022958818406108663</td>\n",
       "      <td>-0.07477658808673338</td>\n",
       "      <td>-0.05530445968405354</td>\n",
       "      <td>-0.08224582351549492</td>\n",
       "      <td>0.01632837882682439</td>\n",
       "      <td>-0.041500098848094545</td>\n",
       "      <td>-0.0941805728200802</td>\n",
       "      <td>0.28546961540051097</td>\n",
       "      <td>-0.17149467802590737</td>\n",
       "      <td>-0.38698649835788596</td>\n",
       "      <td>0.45248867689216205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17694</th>\n",
       "      <td>-0.0027607195002569275</td>\n",
       "      <td>0.015161616015401516</td>\n",
       "      <td>-0.00015080481522030884</td>\n",
       "      <td>-0.008898828074254177</td>\n",
       "      <td>0.03362560819036194</td>\n",
       "      <td>0.04544883330076278</td>\n",
       "      <td>-0.013722334159947523</td>\n",
       "      <td>0.030260440236428283</td>\n",
       "      <td>0.010471057846814721</td>\n",
       "      <td>-0.00581040654310977</td>\n",
       "      <td>-0.07645532608359724</td>\n",
       "      <td>-0.05564638829129943</td>\n",
       "      <td>-0.08026164997788658</td>\n",
       "      <td>0.01530183477859412</td>\n",
       "      <td>-0.044401973073120014</td>\n",
       "      <td>-0.10628765613086276</td>\n",
       "      <td>0.2685603942189898</td>\n",
       "      <td>-0.18908442830728306</td>\n",
       "      <td>-0.38013727514298407</td>\n",
       "      <td>0.45223815690030106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21575</th>\n",
       "      <td>-0.012492351872273363</td>\n",
       "      <td>0.007536452074463551</td>\n",
       "      <td>-0.018506325041302122</td>\n",
       "      <td>-0.017089678195233528</td>\n",
       "      <td>0.039203591806670796</td>\n",
       "      <td>0.049402189390160715</td>\n",
       "      <td>-0.04947986584300032</td>\n",
       "      <td>-0.0017390944407536433</td>\n",
       "      <td>0.029132856185046525</td>\n",
       "      <td>0.023705318512108463</td>\n",
       "      <td>-0.08197748438096963</td>\n",
       "      <td>-0.04510261667408765</td>\n",
       "      <td>-0.07732452362131041</td>\n",
       "      <td>0.010787116155529825</td>\n",
       "      <td>-0.0424167232389132</td>\n",
       "      <td>-0.09101597213974366</td>\n",
       "      <td>0.2843617115570949</td>\n",
       "      <td>-0.18007546849262257</td>\n",
       "      <td>-0.3848179054260254</td>\n",
       "      <td>0.45235627348606405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>-0.01235045476940023</td>\n",
       "      <td>0.015049399836101087</td>\n",
       "      <td>-0.006373908302006143</td>\n",
       "      <td>-0.01705271949295897</td>\n",
       "      <td>0.03086481868227697</td>\n",
       "      <td>0.04687324411927229</td>\n",
       "      <td>-0.018279889892332302</td>\n",
       "      <td>0.027308368323236167</td>\n",
       "      <td>0.008138610585873207</td>\n",
       "      <td>0.013410791733683682</td>\n",
       "      <td>-0.07341634901240468</td>\n",
       "      <td>-0.04886937743955409</td>\n",
       "      <td>-0.08105097164144649</td>\n",
       "      <td>0.015565496498399067</td>\n",
       "      <td>-0.046196054089190274</td>\n",
       "      <td>-0.10226984125146844</td>\n",
       "      <td>0.2798702358660928</td>\n",
       "      <td>-0.1804323343879891</td>\n",
       "      <td>-0.3789964741073459</td>\n",
       "      <td>0.45639494752668475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.007469163903071746</td>\n",
       "      <td>0.017867189762639065</td>\n",
       "      <td>-0.003439424139922302</td>\n",
       "      <td>-0.004786975855263425</td>\n",
       "      <td>0.040547943942924485</td>\n",
       "      <td>0.043420687925034</td>\n",
       "      <td>-0.013967232158243218</td>\n",
       "      <td>0.0249142186643154</td>\n",
       "      <td>0.01727036287935049</td>\n",
       "      <td>0.005141155684238993</td>\n",
       "      <td>-0.07966828092056162</td>\n",
       "      <td>-0.04693657712218827</td>\n",
       "      <td>-0.0733919514589669</td>\n",
       "      <td>0.013653007484105069</td>\n",
       "      <td>-0.04173683894229779</td>\n",
       "      <td>-0.09009340196555736</td>\n",
       "      <td>0.27144392816459434</td>\n",
       "      <td>-0.17931756841785768</td>\n",
       "      <td>-0.37222152854882035</td>\n",
       "      <td>0.4622417737455929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>-0.006360734793099951</td>\n",
       "      <td>0.00640353517271036</td>\n",
       "      <td>-0.005205395738912323</td>\n",
       "      <td>-0.004815933581395752</td>\n",
       "      <td>0.040161483699752046</td>\n",
       "      <td>0.046910731188253126</td>\n",
       "      <td>-0.024982667019932812</td>\n",
       "      <td>0.01982178420875501</td>\n",
       "      <td>0.03699982860245536</td>\n",
       "      <td>0.013944054913862471</td>\n",
       "      <td>-0.08127550237206169</td>\n",
       "      <td>-0.03887685566013189</td>\n",
       "      <td>-0.07059276071773406</td>\n",
       "      <td>0.009016335184695272</td>\n",
       "      <td>-0.04053967792375487</td>\n",
       "      <td>-0.08023869198687533</td>\n",
       "      <td>0.2706622867975363</td>\n",
       "      <td>-0.18664192322595724</td>\n",
       "      <td>-0.3725823687946409</td>\n",
       "      <td>0.46420805765292944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23654</th>\n",
       "      <td>-0.00018032971846078055</td>\n",
       "      <td>0.01959235514227248</td>\n",
       "      <td>-0.0001396403620740484</td>\n",
       "      <td>-0.014295608075968275</td>\n",
       "      <td>0.030779512613087798</td>\n",
       "      <td>0.046512690662699904</td>\n",
       "      <td>-0.010135261572553154</td>\n",
       "      <td>0.029541436778484458</td>\n",
       "      <td>0.003917179058642843</td>\n",
       "      <td>0.007990081856353871</td>\n",
       "      <td>-0.09077128107066591</td>\n",
       "      <td>-0.04737149198136056</td>\n",
       "      <td>-0.0792445543793723</td>\n",
       "      <td>0.012392829710619132</td>\n",
       "      <td>-0.0410656674989789</td>\n",
       "      <td>-0.1015698743121931</td>\n",
       "      <td>0.2818575712365185</td>\n",
       "      <td>-0.18162645615113526</td>\n",
       "      <td>-0.378009971048783</td>\n",
       "      <td>0.45224658389227085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23184 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0                     1                        2   \\\n",
       "5653      -0.00706682954747062   0.01996781248263679    -0.013601513556938886   \n",
       "15912   -0.0013864726187148054   0.02203218482619284     0.004126875728351459   \n",
       "20717     0.008983750991099323   0.02368557540650229   0.00013234988294686157   \n",
       "10385    -0.014656537184149743   0.01842433754565184    -0.015861016172668396   \n",
       "17694   -0.0027607195002569275  0.015161616015401516  -0.00015080481522030884   \n",
       "...                        ...                   ...                      ...   \n",
       "21575    -0.012492351872273363  0.007536452074463551    -0.018506325041302122   \n",
       "5390      -0.01235045476940023  0.015049399836101087    -0.006373908302006143   \n",
       "860       0.007469163903071746  0.017867189762639065    -0.003439424139922302   \n",
       "15795    -0.006360734793099951   0.00640353517271036    -0.005205395738912323   \n",
       "23654  -0.00018032971846078055   0.01959235514227248   -0.0001396403620740484   \n",
       "\n",
       "                          3                     4                     5   \\\n",
       "5653    -0.01077419164515025  0.034717422380397385  0.052683456591645104   \n",
       "15912  -0.014449601574878759   0.02737126940350991   0.04360691650919097   \n",
       "20717  -0.006080677074359924  0.040763485880758045   0.04409194367300137   \n",
       "10385   -0.02357154274569814   0.03668313008591027   0.04792766738255472   \n",
       "17694  -0.008898828074254177   0.03362560819036194   0.04544883330076278   \n",
       "...                      ...                   ...                   ...   \n",
       "21575  -0.017089678195233528  0.039203591806670796  0.049402189390160715   \n",
       "5390    -0.01705271949295897   0.03086481868227697   0.04687324411927229   \n",
       "860    -0.004786975855263425  0.040547943942924485     0.043420687925034   \n",
       "15795  -0.004815933581395752  0.040161483699752046  0.046910731188253126   \n",
       "23654  -0.014295608075968275  0.030779512613087798  0.046512690662699904   \n",
       "\n",
       "                          6                       7                       8   \\\n",
       "5653    -0.02132001722615363    0.025572076695761434  -0.0008094727317592851   \n",
       "15912     -0.011711142661667     0.03003467550506994    0.015308702600998775   \n",
       "20717  -0.011764170012840455    0.026934225969106752      0.0189247682271187   \n",
       "10385   -0.03691827117644335    0.015225870158565415  -0.0018293998930287564   \n",
       "17694  -0.013722334159947523    0.030260440236428283    0.010471057846814721   \n",
       "...                      ...                     ...                     ...   \n",
       "21575   -0.04947986584300032  -0.0017390944407536433    0.029132856185046525   \n",
       "5390   -0.018279889892332302    0.027308368323236167    0.008138610585873207   \n",
       "860    -0.013967232158243218      0.0249142186643154     0.01727036287935049   \n",
       "15795  -0.024982667019932812     0.01982178420875501     0.03699982860245536   \n",
       "23654  -0.010135261572553154    0.029541436778484458    0.003917179058642843   \n",
       "\n",
       "                         9                     10                     11  \\\n",
       "5653   0.007029286265343864  -0.07567065814090473   -0.05867228435804996   \n",
       "15912  0.003992990647578156  -0.08925564643629934  -0.049872565095820366   \n",
       "20717  0.008414136009633578  -0.09445401626136199   -0.04720036891025782   \n",
       "10385  0.022958818406108663  -0.07477658808673338   -0.05530445968405354   \n",
       "17694  -0.00581040654310977  -0.07645532608359724   -0.05564638829129943   \n",
       "...                     ...                   ...                    ...   \n",
       "21575  0.023705318512108463  -0.08197748438096963   -0.04510261667408765   \n",
       "5390   0.013410791733683682  -0.07341634901240468   -0.04886937743955409   \n",
       "860    0.005141155684238993  -0.07966828092056162   -0.04693657712218827   \n",
       "15795  0.013944054913862471  -0.08127550237206169   -0.03887685566013189   \n",
       "23654  0.007990081856353871  -0.09077128107066591   -0.04737149198136056   \n",
       "\n",
       "                         12                    13                     14  \\\n",
       "5653   -0.08707858990512889  0.013089384874465313  -0.043677887445114354   \n",
       "15912  -0.07808278877094918  0.014014008626177469   -0.04130462270580382   \n",
       "20717  -0.07217291057263174  0.012880380718391524   -0.03792636959529403   \n",
       "10385  -0.08224582351549492   0.01632837882682439  -0.041500098848094545   \n",
       "17694  -0.08026164997788658   0.01530183477859412  -0.044401973073120014   \n",
       "...                     ...                   ...                    ...   \n",
       "21575  -0.07732452362131041  0.010787116155529825    -0.0424167232389132   \n",
       "5390   -0.08105097164144649  0.015565496498399067  -0.046196054089190274   \n",
       "860     -0.0733919514589669  0.013653007484105069   -0.04173683894229779   \n",
       "15795  -0.07059276071773406  0.009016335184695272   -0.04053967792375487   \n",
       "23654   -0.0792445543793723  0.012392829710619132    -0.0410656674989789   \n",
       "\n",
       "                         15                   16                    17  \\\n",
       "5653   -0.10073068651983196    0.282148170545026  -0.17623799561883682   \n",
       "15912  -0.10628305586060688   0.2773202256337039  -0.19328804736547517   \n",
       "20717   -0.0924403506982846  0.27535202020450017  -0.17923264435016648   \n",
       "10385   -0.0941805728200802  0.28546961540051097  -0.17149467802590737   \n",
       "17694  -0.10628765613086276   0.2685603942189898  -0.18908442830728306   \n",
       "...                     ...                  ...                   ...   \n",
       "21575  -0.09101597213974366   0.2843617115570949  -0.18007546849262257   \n",
       "5390   -0.10226984125146844   0.2798702358660928   -0.1804323343879891   \n",
       "860    -0.09009340196555736  0.27144392816459434  -0.17931756841785768   \n",
       "15795  -0.08023869198687533   0.2706622867975363  -0.18664192322595724   \n",
       "23654   -0.1015698743121931   0.2818575712365185  -0.18162645615113526   \n",
       "\n",
       "                         18                   19  \n",
       "5653    -0.3917241754966813   0.4433238150568696  \n",
       "15912  -0.36903954899347974  0.45759566815644964  \n",
       "20717  -0.36526467479747377   0.4648126223762734  \n",
       "10385  -0.38698649835788596  0.45248867689216205  \n",
       "17694  -0.38013727514298407  0.45223815690030106  \n",
       "...                     ...                  ...  \n",
       "21575   -0.3848179054260254  0.45235627348606405  \n",
       "5390    -0.3789964741073459  0.45639494752668475  \n",
       "860    -0.37222152854882035   0.4622417737455929  \n",
       "15795   -0.3725823687946409  0.46420805765292944  \n",
       "23654    -0.378009971048783  0.45224658389227085  \n",
       "\n",
       "[23184 rows x 20 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T01:11:30.637724Z",
     "iopub.status.busy": "2022-11-03T01:11:30.637434Z",
     "iopub.status.idle": "2022-11-03T01:11:30.663532Z",
     "shell.execute_reply": "2022-11-03T01:11:30.662689Z",
     "shell.execute_reply.started": "2022-11-03T01:11:30.637697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16502</th>\n",
       "      <td>-0.01007100484737127</td>\n",
       "      <td>0.020716818481138568</td>\n",
       "      <td>-0.017176734787559638</td>\n",
       "      <td>-0.01838827471067084</td>\n",
       "      <td>0.033554893479648434</td>\n",
       "      <td>0.04428525120637482</td>\n",
       "      <td>-0.027834068706951945</td>\n",
       "      <td>0.022566163781803192</td>\n",
       "      <td>-0.0066600590546774426</td>\n",
       "      <td>0.023225382931541833</td>\n",
       "      <td>-0.07381433594926465</td>\n",
       "      <td>-0.05617489168319635</td>\n",
       "      <td>-0.08785572220577018</td>\n",
       "      <td>0.021613334732203993</td>\n",
       "      <td>-0.046991639331880414</td>\n",
       "      <td>-0.10207899094263954</td>\n",
       "      <td>0.2886387793029227</td>\n",
       "      <td>-0.17216561115687576</td>\n",
       "      <td>-0.38954958955689173</td>\n",
       "      <td>0.4462877900862112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>-0.0019297180877411893</td>\n",
       "      <td>0.02377931755653567</td>\n",
       "      <td>-0.00834142194433107</td>\n",
       "      <td>-0.014418369148811583</td>\n",
       "      <td>0.035440501508056006</td>\n",
       "      <td>0.04597573673905089</td>\n",
       "      <td>-0.020266163364201988</td>\n",
       "      <td>0.02615064098782714</td>\n",
       "      <td>-0.0018017498354391498</td>\n",
       "      <td>0.017375482372985897</td>\n",
       "      <td>-0.09290678693156545</td>\n",
       "      <td>-0.04780187087296894</td>\n",
       "      <td>-0.07391945272619779</td>\n",
       "      <td>0.01078674431378279</td>\n",
       "      <td>-0.03330525567945484</td>\n",
       "      <td>-0.08167433042017465</td>\n",
       "      <td>0.27826092009386305</td>\n",
       "      <td>-0.16912448384608683</td>\n",
       "      <td>-0.37657818321694325</td>\n",
       "      <td>0.4618160872004967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731</th>\n",
       "      <td>0.0012389976143852243</td>\n",
       "      <td>0.007089151173850389</td>\n",
       "      <td>-0.004011220948533995</td>\n",
       "      <td>0.010207740919501648</td>\n",
       "      <td>0.05137561977385477</td>\n",
       "      <td>0.04124302048486774</td>\n",
       "      <td>-0.008916390827561784</td>\n",
       "      <td>0.035747224214369724</td>\n",
       "      <td>0.02933851521986389</td>\n",
       "      <td>0.005701084664190707</td>\n",
       "      <td>-0.08456084252553966</td>\n",
       "      <td>-0.04028246491230437</td>\n",
       "      <td>-0.07377215109535244</td>\n",
       "      <td>0.010584159224145268</td>\n",
       "      <td>-0.0436335854197164</td>\n",
       "      <td>-0.07296048162270928</td>\n",
       "      <td>0.268239850127469</td>\n",
       "      <td>-0.19371110432058614</td>\n",
       "      <td>-0.37851156066349945</td>\n",
       "      <td>0.4537248262942163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8663</th>\n",
       "      <td>-0.0076030583364627095</td>\n",
       "      <td>0.009252273952006363</td>\n",
       "      <td>-0.007099489257961977</td>\n",
       "      <td>-0.008877561647386756</td>\n",
       "      <td>0.042884880680503557</td>\n",
       "      <td>0.051200304302165024</td>\n",
       "      <td>-0.025608607086542178</td>\n",
       "      <td>0.022252029123774265</td>\n",
       "      <td>0.0216680995101342</td>\n",
       "      <td>0.008538175644571312</td>\n",
       "      <td>-0.07523174673260655</td>\n",
       "      <td>-0.048718221302260646</td>\n",
       "      <td>-0.0806891091830039</td>\n",
       "      <td>0.010738761683387565</td>\n",
       "      <td>-0.044826576664672754</td>\n",
       "      <td>-0.08844954155210871</td>\n",
       "      <td>0.27257075435481964</td>\n",
       "      <td>-0.18810596614348468</td>\n",
       "      <td>-0.3830053933430463</td>\n",
       "      <td>0.45266960957087576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27605</th>\n",
       "      <td>-0.002767845586134885</td>\n",
       "      <td>0.022326212941911748</td>\n",
       "      <td>-0.014901467121274868</td>\n",
       "      <td>-0.013510348025311862</td>\n",
       "      <td>0.037172027291603</td>\n",
       "      <td>0.05084247472553849</td>\n",
       "      <td>-0.03355155905377739</td>\n",
       "      <td>0.016681167367759712</td>\n",
       "      <td>0.007436348357913058</td>\n",
       "      <td>0.01682447942231994</td>\n",
       "      <td>-0.08225489993209821</td>\n",
       "      <td>-0.05627264224646748</td>\n",
       "      <td>-0.08249365308857856</td>\n",
       "      <td>0.012853009292391734</td>\n",
       "      <td>-0.03816170748876463</td>\n",
       "      <td>-0.08560006906933124</td>\n",
       "      <td>0.2783737979804722</td>\n",
       "      <td>-0.17400792114153849</td>\n",
       "      <td>-0.38857717925172436</td>\n",
       "      <td>0.4501042402747965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18893</th>\n",
       "      <td>0.00464730405672805</td>\n",
       "      <td>0.03380839553079834</td>\n",
       "      <td>0.0005486051171583292</td>\n",
       "      <td>-0.01709772429899984</td>\n",
       "      <td>0.03028631518707873</td>\n",
       "      <td>0.05542111212030177</td>\n",
       "      <td>-0.011331479349099014</td>\n",
       "      <td>0.04407142607380105</td>\n",
       "      <td>-0.010823214501227748</td>\n",
       "      <td>0.008859875509131794</td>\n",
       "      <td>-0.08926864562969596</td>\n",
       "      <td>-0.06562044752457497</td>\n",
       "      <td>-0.09265221716959703</td>\n",
       "      <td>0.015122803784022427</td>\n",
       "      <td>-0.03825755808963302</td>\n",
       "      <td>-0.09310025513359693</td>\n",
       "      <td>0.272900808559948</td>\n",
       "      <td>-0.18351527328818218</td>\n",
       "      <td>-0.3871547271512466</td>\n",
       "      <td>0.44572282949083186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>-0.005680721333589066</td>\n",
       "      <td>0.017120178307999265</td>\n",
       "      <td>-0.013564684618772431</td>\n",
       "      <td>-0.008854246488349005</td>\n",
       "      <td>0.04586079923097383</td>\n",
       "      <td>0.04947653078304773</td>\n",
       "      <td>-0.027237487305802378</td>\n",
       "      <td>0.023799184587868775</td>\n",
       "      <td>0.01784108394248919</td>\n",
       "      <td>0.023893042222004047</td>\n",
       "      <td>-0.07861710070886395</td>\n",
       "      <td>-0.04849666560703719</td>\n",
       "      <td>-0.08317168283614923</td>\n",
       "      <td>0.013414436663839627</td>\n",
       "      <td>-0.04504067326409065</td>\n",
       "      <td>-0.0810076702657071</td>\n",
       "      <td>0.28108067279512233</td>\n",
       "      <td>-0.1825027948347005</td>\n",
       "      <td>-0.381540029482408</td>\n",
       "      <td>0.4533358744057742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>-0.010295576337912228</td>\n",
       "      <td>0.002239035001957661</td>\n",
       "      <td>-0.013131519538927928</td>\n",
       "      <td>-0.021093346116096614</td>\n",
       "      <td>0.04251803377481937</td>\n",
       "      <td>0.05326284237088483</td>\n",
       "      <td>-0.04087985377781287</td>\n",
       "      <td>-0.0037498731769662996</td>\n",
       "      <td>0.015206931646240379</td>\n",
       "      <td>0.02667557115335316</td>\n",
       "      <td>-0.09530519445043481</td>\n",
       "      <td>-0.03702161445712074</td>\n",
       "      <td>-0.07100497939176441</td>\n",
       "      <td>0.0051061358210479834</td>\n",
       "      <td>-0.03425768390395444</td>\n",
       "      <td>-0.08363060594936989</td>\n",
       "      <td>0.29281802336707907</td>\n",
       "      <td>-0.16135882496750553</td>\n",
       "      <td>-0.3936704034800858</td>\n",
       "      <td>0.4478827433546162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11756</th>\n",
       "      <td>-0.019038924893094084</td>\n",
       "      <td>0.0044116757211753125</td>\n",
       "      <td>0.0017544928638969061</td>\n",
       "      <td>-0.017825186749621066</td>\n",
       "      <td>0.024778116402732586</td>\n",
       "      <td>0.050799784122078334</td>\n",
       "      <td>-0.011555332326151701</td>\n",
       "      <td>0.03350064806505034</td>\n",
       "      <td>0.019036370701122778</td>\n",
       "      <td>0.006021548932360321</td>\n",
       "      <td>-0.06165240773535454</td>\n",
       "      <td>-0.047774615654736334</td>\n",
       "      <td>-0.08680650024008912</td>\n",
       "      <td>0.015665217003558274</td>\n",
       "      <td>-0.05431100121371139</td>\n",
       "      <td>-0.11687763826680307</td>\n",
       "      <td>0.28271968693622035</td>\n",
       "      <td>-0.19647570032568484</td>\n",
       "      <td>-0.3842049920497163</td>\n",
       "      <td>0.44593287517987384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23790</th>\n",
       "      <td>0.0055552497412068675</td>\n",
       "      <td>0.022527759612509697</td>\n",
       "      <td>-0.005202156576243314</td>\n",
       "      <td>-0.014250040430613238</td>\n",
       "      <td>0.05097754495547652</td>\n",
       "      <td>0.04311605619920437</td>\n",
       "      <td>-0.02081221810099904</td>\n",
       "      <td>0.018640773079235746</td>\n",
       "      <td>0.009643611930912793</td>\n",
       "      <td>0.026004224592311817</td>\n",
       "      <td>-0.09665909057690038</td>\n",
       "      <td>-0.04473020097610042</td>\n",
       "      <td>-0.07359734190054087</td>\n",
       "      <td>0.014004832227723767</td>\n",
       "      <td>-0.03686095927806684</td>\n",
       "      <td>-0.08061996119266207</td>\n",
       "      <td>0.2931626300619106</td>\n",
       "      <td>-0.16928204009779776</td>\n",
       "      <td>-0.37855617927782464</td>\n",
       "      <td>0.4533998424356634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5797 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0                      1                      2   \\\n",
       "16502    -0.01007100484737127   0.020716818481138568  -0.017176734787559638   \n",
       "843    -0.0019297180877411893    0.02377931755653567   -0.00834142194433107   \n",
       "5731    0.0012389976143852243   0.007089151173850389  -0.004011220948533995   \n",
       "8663   -0.0076030583364627095   0.009252273952006363  -0.007099489257961977   \n",
       "27605   -0.002767845586134885   0.022326212941911748  -0.014901467121274868   \n",
       "...                       ...                    ...                    ...   \n",
       "18893     0.00464730405672805    0.03380839553079834  0.0005486051171583292   \n",
       "2698    -0.005680721333589066   0.017120178307999265  -0.013564684618772431   \n",
       "4199    -0.010295576337912228   0.002239035001957661  -0.013131519538927928   \n",
       "11756   -0.019038924893094084  0.0044116757211753125  0.0017544928638969061   \n",
       "23790   0.0055552497412068675   0.022527759612509697  -0.005202156576243314   \n",
       "\n",
       "                          3                     4                     5   \\\n",
       "16502   -0.01838827471067084  0.033554893479648434   0.04428525120637482   \n",
       "843    -0.014418369148811583  0.035440501508056006   0.04597573673905089   \n",
       "5731    0.010207740919501648   0.05137561977385477   0.04124302048486774   \n",
       "8663   -0.008877561647386756  0.042884880680503557  0.051200304302165024   \n",
       "27605  -0.013510348025311862     0.037172027291603   0.05084247472553849   \n",
       "...                      ...                   ...                   ...   \n",
       "18893   -0.01709772429899984   0.03028631518707873   0.05542111212030177   \n",
       "2698   -0.008854246488349005   0.04586079923097383   0.04947653078304773   \n",
       "4199   -0.021093346116096614   0.04251803377481937   0.05326284237088483   \n",
       "11756  -0.017825186749621066  0.024778116402732586  0.050799784122078334   \n",
       "23790  -0.014250040430613238   0.05097754495547652   0.04311605619920437   \n",
       "\n",
       "                          6                       7                       8   \\\n",
       "16502  -0.027834068706951945    0.022566163781803192  -0.0066600590546774426   \n",
       "843    -0.020266163364201988     0.02615064098782714  -0.0018017498354391498   \n",
       "5731   -0.008916390827561784    0.035747224214369724     0.02933851521986389   \n",
       "8663   -0.025608607086542178    0.022252029123774265      0.0216680995101342   \n",
       "27605   -0.03355155905377739    0.016681167367759712    0.007436348357913058   \n",
       "...                      ...                     ...                     ...   \n",
       "18893  -0.011331479349099014     0.04407142607380105   -0.010823214501227748   \n",
       "2698   -0.027237487305802378    0.023799184587868775     0.01784108394248919   \n",
       "4199    -0.04087985377781287  -0.0037498731769662996    0.015206931646240379   \n",
       "11756  -0.011555332326151701     0.03350064806505034    0.019036370701122778   \n",
       "23790   -0.02081221810099904    0.018640773079235746    0.009643611930912793   \n",
       "\n",
       "                         9                     10                     11  \\\n",
       "16502  0.023225382931541833  -0.07381433594926465   -0.05617489168319635   \n",
       "843    0.017375482372985897  -0.09290678693156545   -0.04780187087296894   \n",
       "5731   0.005701084664190707  -0.08456084252553966   -0.04028246491230437   \n",
       "8663   0.008538175644571312  -0.07523174673260655  -0.048718221302260646   \n",
       "27605   0.01682447942231994  -0.08225489993209821   -0.05627264224646748   \n",
       "...                     ...                   ...                    ...   \n",
       "18893  0.008859875509131794  -0.08926864562969596   -0.06562044752457497   \n",
       "2698   0.023893042222004047  -0.07861710070886395   -0.04849666560703719   \n",
       "4199    0.02667557115335316  -0.09530519445043481   -0.03702161445712074   \n",
       "11756  0.006021548932360321  -0.06165240773535454  -0.047774615654736334   \n",
       "23790  0.026004224592311817  -0.09665909057690038   -0.04473020097610042   \n",
       "\n",
       "                         12                     13                     14  \\\n",
       "16502  -0.08785572220577018   0.021613334732203993  -0.046991639331880414   \n",
       "843    -0.07391945272619779    0.01078674431378279   -0.03330525567945484   \n",
       "5731   -0.07377215109535244   0.010584159224145268    -0.0436335854197164   \n",
       "8663    -0.0806891091830039   0.010738761683387565  -0.044826576664672754   \n",
       "27605  -0.08249365308857856   0.012853009292391734   -0.03816170748876463   \n",
       "...                     ...                    ...                    ...   \n",
       "18893  -0.09265221716959703   0.015122803784022427   -0.03825755808963302   \n",
       "2698   -0.08317168283614923   0.013414436663839627   -0.04504067326409065   \n",
       "4199   -0.07100497939176441  0.0051061358210479834   -0.03425768390395444   \n",
       "11756  -0.08680650024008912   0.015665217003558274   -0.05431100121371139   \n",
       "23790  -0.07359734190054087   0.014004832227723767   -0.03686095927806684   \n",
       "\n",
       "                         15                   16                    17  \\\n",
       "16502  -0.10207899094263954   0.2886387793029227  -0.17216561115687576   \n",
       "843    -0.08167433042017465  0.27826092009386305  -0.16912448384608683   \n",
       "5731   -0.07296048162270928    0.268239850127469  -0.19371110432058614   \n",
       "8663   -0.08844954155210871  0.27257075435481964  -0.18810596614348468   \n",
       "27605  -0.08560006906933124   0.2783737979804722  -0.17400792114153849   \n",
       "...                     ...                  ...                   ...   \n",
       "18893  -0.09310025513359693    0.272900808559948  -0.18351527328818218   \n",
       "2698    -0.0810076702657071  0.28108067279512233   -0.1825027948347005   \n",
       "4199   -0.08363060594936989  0.29281802336707907  -0.16135882496750553   \n",
       "11756  -0.11687763826680307  0.28271968693622035  -0.19647570032568484   \n",
       "23790  -0.08061996119266207   0.2931626300619106  -0.16928204009779776   \n",
       "\n",
       "                         18                   19  \n",
       "16502  -0.38954958955689173   0.4462877900862112  \n",
       "843    -0.37657818321694325   0.4618160872004967  \n",
       "5731   -0.37851156066349945   0.4537248262942163  \n",
       "8663    -0.3830053933430463  0.45266960957087576  \n",
       "27605  -0.38857717925172436   0.4501042402747965  \n",
       "...                     ...                  ...  \n",
       "18893   -0.3871547271512466  0.44572282949083186  \n",
       "2698     -0.381540029482408   0.4533358744057742  \n",
       "4199    -0.3936704034800858   0.4478827433546162  \n",
       "11756   -0.3842049920497163  0.44593287517987384  \n",
       "23790  -0.37855617927782464   0.4533998424356634  \n",
       "\n",
       "[5797 rows x 20 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T01:11:30.664737Z",
     "iopub.status.busy": "2022-11-03T01:11:30.664430Z",
     "iopub.status.idle": "2022-11-03T01:11:30.722378Z",
     "shell.execute_reply": "2022-11-03T01:11:30.721278Z",
     "shell.execute_reply.started": "2022-11-03T01:11:30.664708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T01:11:30.724364Z",
     "iopub.status.busy": "2022-11-03T01:11:30.723861Z",
     "iopub.status.idle": "2022-11-03T01:11:31.417535Z",
     "shell.execute_reply": "2022-11-03T01:11:31.416188Z",
     "shell.execute_reply.started": "2022-11-03T01:11:30.724329Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "columns = [f'Acid {x+1}' for x in range(len(train.columns))]\n",
    "imputer1 = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer1.fit(train)\n",
    "train_data = pd.DataFrame(imputer1.transform(train), columns= columns)\n",
    "\n",
    "imputer2 = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer2.fit(train)\n",
    "test_data = pd.DataFrame(imputer2.transform(test), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T01:11:31.419334Z",
     "iopub.status.busy": "2022-11-03T01:11:31.418981Z",
     "iopub.status.idle": "2022-11-03T01:11:31.448445Z",
     "shell.execute_reply": "2022-11-03T01:11:31.447233Z",
     "shell.execute_reply.started": "2022-11-03T01:11:31.419296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acid 1</th>\n",
       "      <th>Acid 2</th>\n",
       "      <th>Acid 3</th>\n",
       "      <th>Acid 4</th>\n",
       "      <th>Acid 5</th>\n",
       "      <th>Acid 6</th>\n",
       "      <th>Acid 7</th>\n",
       "      <th>Acid 8</th>\n",
       "      <th>Acid 9</th>\n",
       "      <th>Acid 10</th>\n",
       "      <th>Acid 11</th>\n",
       "      <th>Acid 12</th>\n",
       "      <th>Acid 13</th>\n",
       "      <th>Acid 14</th>\n",
       "      <th>Acid 15</th>\n",
       "      <th>Acid 16</th>\n",
       "      <th>Acid 17</th>\n",
       "      <th>Acid 18</th>\n",
       "      <th>Acid 19</th>\n",
       "      <th>Acid 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007067</td>\n",
       "      <td>0.019968</td>\n",
       "      <td>-0.013602</td>\n",
       "      <td>-0.010774</td>\n",
       "      <td>0.034717</td>\n",
       "      <td>0.052683</td>\n",
       "      <td>-0.021320</td>\n",
       "      <td>0.025572</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>-0.075671</td>\n",
       "      <td>-0.058672</td>\n",
       "      <td>-0.087079</td>\n",
       "      <td>0.013089</td>\n",
       "      <td>-0.043678</td>\n",
       "      <td>-0.100731</td>\n",
       "      <td>0.282148</td>\n",
       "      <td>-0.176238</td>\n",
       "      <td>-0.391724</td>\n",
       "      <td>0.443324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001386</td>\n",
       "      <td>0.022032</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>-0.014450</td>\n",
       "      <td>0.027371</td>\n",
       "      <td>0.043607</td>\n",
       "      <td>-0.011711</td>\n",
       "      <td>0.030035</td>\n",
       "      <td>0.015309</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>-0.089256</td>\n",
       "      <td>-0.049873</td>\n",
       "      <td>-0.078083</td>\n",
       "      <td>0.014014</td>\n",
       "      <td>-0.041305</td>\n",
       "      <td>-0.106283</td>\n",
       "      <td>0.277320</td>\n",
       "      <td>-0.193288</td>\n",
       "      <td>-0.369040</td>\n",
       "      <td>0.457596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008984</td>\n",
       "      <td>0.023686</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>-0.006081</td>\n",
       "      <td>0.040763</td>\n",
       "      <td>0.044092</td>\n",
       "      <td>-0.011764</td>\n",
       "      <td>0.026934</td>\n",
       "      <td>0.018925</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>-0.094454</td>\n",
       "      <td>-0.047200</td>\n",
       "      <td>-0.072173</td>\n",
       "      <td>0.012880</td>\n",
       "      <td>-0.037926</td>\n",
       "      <td>-0.092440</td>\n",
       "      <td>0.275352</td>\n",
       "      <td>-0.179233</td>\n",
       "      <td>-0.365265</td>\n",
       "      <td>0.464813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.014657</td>\n",
       "      <td>0.018424</td>\n",
       "      <td>-0.015861</td>\n",
       "      <td>-0.023572</td>\n",
       "      <td>0.036683</td>\n",
       "      <td>0.047928</td>\n",
       "      <td>-0.036918</td>\n",
       "      <td>0.015226</td>\n",
       "      <td>-0.001829</td>\n",
       "      <td>0.022959</td>\n",
       "      <td>-0.074777</td>\n",
       "      <td>-0.055304</td>\n",
       "      <td>-0.082246</td>\n",
       "      <td>0.016328</td>\n",
       "      <td>-0.041500</td>\n",
       "      <td>-0.094181</td>\n",
       "      <td>0.285470</td>\n",
       "      <td>-0.171495</td>\n",
       "      <td>-0.386986</td>\n",
       "      <td>0.452489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.015162</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>-0.008899</td>\n",
       "      <td>0.033626</td>\n",
       "      <td>0.045449</td>\n",
       "      <td>-0.013722</td>\n",
       "      <td>0.030260</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>-0.005810</td>\n",
       "      <td>-0.076455</td>\n",
       "      <td>-0.055646</td>\n",
       "      <td>-0.080262</td>\n",
       "      <td>0.015302</td>\n",
       "      <td>-0.044402</td>\n",
       "      <td>-0.106288</td>\n",
       "      <td>0.268560</td>\n",
       "      <td>-0.189084</td>\n",
       "      <td>-0.380137</td>\n",
       "      <td>0.452238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23179</th>\n",
       "      <td>-0.012492</td>\n",
       "      <td>0.007536</td>\n",
       "      <td>-0.018506</td>\n",
       "      <td>-0.017090</td>\n",
       "      <td>0.039204</td>\n",
       "      <td>0.049402</td>\n",
       "      <td>-0.049480</td>\n",
       "      <td>-0.001739</td>\n",
       "      <td>0.029133</td>\n",
       "      <td>0.023705</td>\n",
       "      <td>-0.081977</td>\n",
       "      <td>-0.045103</td>\n",
       "      <td>-0.077325</td>\n",
       "      <td>0.010787</td>\n",
       "      <td>-0.042417</td>\n",
       "      <td>-0.091016</td>\n",
       "      <td>0.284362</td>\n",
       "      <td>-0.180075</td>\n",
       "      <td>-0.384818</td>\n",
       "      <td>0.452356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23180</th>\n",
       "      <td>-0.012350</td>\n",
       "      <td>0.015049</td>\n",
       "      <td>-0.006374</td>\n",
       "      <td>-0.017053</td>\n",
       "      <td>0.030865</td>\n",
       "      <td>0.046873</td>\n",
       "      <td>-0.018280</td>\n",
       "      <td>0.027308</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>-0.073416</td>\n",
       "      <td>-0.048869</td>\n",
       "      <td>-0.081051</td>\n",
       "      <td>0.015565</td>\n",
       "      <td>-0.046196</td>\n",
       "      <td>-0.102270</td>\n",
       "      <td>0.279870</td>\n",
       "      <td>-0.180432</td>\n",
       "      <td>-0.378996</td>\n",
       "      <td>0.456395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23181</th>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.017867</td>\n",
       "      <td>-0.003439</td>\n",
       "      <td>-0.004787</td>\n",
       "      <td>0.040548</td>\n",
       "      <td>0.043421</td>\n",
       "      <td>-0.013967</td>\n",
       "      <td>0.024914</td>\n",
       "      <td>0.017270</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>-0.079668</td>\n",
       "      <td>-0.046937</td>\n",
       "      <td>-0.073392</td>\n",
       "      <td>0.013653</td>\n",
       "      <td>-0.041737</td>\n",
       "      <td>-0.090093</td>\n",
       "      <td>0.271444</td>\n",
       "      <td>-0.179318</td>\n",
       "      <td>-0.372222</td>\n",
       "      <td>0.462242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23182</th>\n",
       "      <td>-0.006361</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>-0.005205</td>\n",
       "      <td>-0.004816</td>\n",
       "      <td>0.040161</td>\n",
       "      <td>0.046911</td>\n",
       "      <td>-0.024983</td>\n",
       "      <td>0.019822</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.013944</td>\n",
       "      <td>-0.081276</td>\n",
       "      <td>-0.038877</td>\n",
       "      <td>-0.070593</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>-0.040540</td>\n",
       "      <td>-0.080239</td>\n",
       "      <td>0.270662</td>\n",
       "      <td>-0.186642</td>\n",
       "      <td>-0.372582</td>\n",
       "      <td>0.464208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23183</th>\n",
       "      <td>-0.000180</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>-0.014296</td>\n",
       "      <td>0.030780</td>\n",
       "      <td>0.046513</td>\n",
       "      <td>-0.010135</td>\n",
       "      <td>0.029541</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>-0.090771</td>\n",
       "      <td>-0.047371</td>\n",
       "      <td>-0.079245</td>\n",
       "      <td>0.012393</td>\n",
       "      <td>-0.041066</td>\n",
       "      <td>-0.101570</td>\n",
       "      <td>0.281858</td>\n",
       "      <td>-0.181626</td>\n",
       "      <td>-0.378010</td>\n",
       "      <td>0.452247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23184 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Acid 1    Acid 2    Acid 3    Acid 4    Acid 5    Acid 6    Acid 7  \\\n",
       "0     -0.007067  0.019968 -0.013602 -0.010774  0.034717  0.052683 -0.021320   \n",
       "1     -0.001386  0.022032  0.004127 -0.014450  0.027371  0.043607 -0.011711   \n",
       "2      0.008984  0.023686  0.000132 -0.006081  0.040763  0.044092 -0.011764   \n",
       "3     -0.014657  0.018424 -0.015861 -0.023572  0.036683  0.047928 -0.036918   \n",
       "4     -0.002761  0.015162 -0.000151 -0.008899  0.033626  0.045449 -0.013722   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "23179 -0.012492  0.007536 -0.018506 -0.017090  0.039204  0.049402 -0.049480   \n",
       "23180 -0.012350  0.015049 -0.006374 -0.017053  0.030865  0.046873 -0.018280   \n",
       "23181  0.007469  0.017867 -0.003439 -0.004787  0.040548  0.043421 -0.013967   \n",
       "23182 -0.006361  0.006404 -0.005205 -0.004816  0.040161  0.046911 -0.024983   \n",
       "23183 -0.000180  0.019592 -0.000140 -0.014296  0.030780  0.046513 -0.010135   \n",
       "\n",
       "         Acid 8    Acid 9   Acid 10   Acid 11   Acid 12   Acid 13   Acid 14  \\\n",
       "0      0.025572 -0.000809  0.007029 -0.075671 -0.058672 -0.087079  0.013089   \n",
       "1      0.030035  0.015309  0.003993 -0.089256 -0.049873 -0.078083  0.014014   \n",
       "2      0.026934  0.018925  0.008414 -0.094454 -0.047200 -0.072173  0.012880   \n",
       "3      0.015226 -0.001829  0.022959 -0.074777 -0.055304 -0.082246  0.016328   \n",
       "4      0.030260  0.010471 -0.005810 -0.076455 -0.055646 -0.080262  0.015302   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "23179 -0.001739  0.029133  0.023705 -0.081977 -0.045103 -0.077325  0.010787   \n",
       "23180  0.027308  0.008139  0.013411 -0.073416 -0.048869 -0.081051  0.015565   \n",
       "23181  0.024914  0.017270  0.005141 -0.079668 -0.046937 -0.073392  0.013653   \n",
       "23182  0.019822  0.037000  0.013944 -0.081276 -0.038877 -0.070593  0.009016   \n",
       "23183  0.029541  0.003917  0.007990 -0.090771 -0.047371 -0.079245  0.012393   \n",
       "\n",
       "        Acid 15   Acid 16   Acid 17   Acid 18   Acid 19   Acid 20  \n",
       "0     -0.043678 -0.100731  0.282148 -0.176238 -0.391724  0.443324  \n",
       "1     -0.041305 -0.106283  0.277320 -0.193288 -0.369040  0.457596  \n",
       "2     -0.037926 -0.092440  0.275352 -0.179233 -0.365265  0.464813  \n",
       "3     -0.041500 -0.094181  0.285470 -0.171495 -0.386986  0.452489  \n",
       "4     -0.044402 -0.106288  0.268560 -0.189084 -0.380137  0.452238  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "23179 -0.042417 -0.091016  0.284362 -0.180075 -0.384818  0.452356  \n",
       "23180 -0.046196 -0.102270  0.279870 -0.180432 -0.378996  0.456395  \n",
       "23181 -0.041737 -0.090093  0.271444 -0.179318 -0.372222  0.462242  \n",
       "23182 -0.040540 -0.080239  0.270662 -0.186642 -0.372582  0.464208  \n",
       "23183 -0.041066 -0.101570  0.281858 -0.181626 -0.378010  0.452247  \n",
       "\n",
       "[23184 rows x 20 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T01:11:31.450144Z",
     "iopub.status.busy": "2022-11-03T01:11:31.449813Z",
     "iopub.status.idle": "2022-11-03T01:11:31.464622Z",
     "shell.execute_reply": "2022-11-03T01:11:31.463383Z",
     "shell.execute_reply.started": "2022-11-03T01:11:31.450113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().values.any()\n",
    "test_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T01:11:31.467888Z",
     "iopub.status.busy": "2022-11-03T01:11:31.467136Z",
     "iopub.status.idle": "2022-11-03T01:11:31.474494Z",
     "shell.execute_reply": "2022-11-03T01:11:31.473278Z",
     "shell.execute_reply.started": "2022-11-03T01:11:31.467847Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T01:11:31.477249Z",
     "iopub.status.busy": "2022-11-03T01:11:31.476169Z",
     "iopub.status.idle": "2022-11-03T01:11:31.489716Z",
     "shell.execute_reply": "2022-11-03T01:11:31.488710Z",
     "shell.execute_reply.started": "2022-11-03T01:11:31.477184Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a DataLoader \n",
    "\n",
    "# Train Dataloader\n",
    "class TrainReview(Dataset):\n",
    "    \n",
    "    # Initialize class variables\n",
    "    def __init__(self, X, y, transform=torch.tensor):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    # Overwrite __getitem__ method\n",
    "    def __getitem__(self, index):\n",
    "       \n",
    "        review = self.X.iloc[index]\n",
    "        label = self.y.iloc[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            review = self.transform(review, dtype=torch.float32)\n",
    "            label = self.transform(label, dtype=torch.float32)\n",
    "\n",
    "        return review,label\n",
    "      \n",
    "\n",
    "# Test data loader\n",
    "class TestReview(Dataset):\n",
    "    \n",
    "    # initialize class variables\n",
    "    def __init__(self, X, y, transform=torch.tensor):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    # Overwrite __getitem__ method\n",
    "    def __getitem__(self, index):\n",
    "        review = self.X.iloc[index]\n",
    "        labels = self.y.iloc[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            review = self.transform(review, dtype=torch.float32)\n",
    "            labels = self.transform(labels, dtype=torch.float32)\n",
    "          \n",
    "        return review,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T01:11:31.491147Z",
     "iopub.status.busy": "2022-11-03T01:11:31.490851Z",
     "iopub.status.idle": "2022-11-03T01:11:31.506340Z",
     "shell.execute_reply": "2022-11-03T01:11:31.505143Z",
     "shell.execute_reply.started": "2022-11-03T01:11:31.491119Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(train_data,y_train,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T01:11:31.507681Z",
     "iopub.status.busy": "2022-11-03T01:11:31.507388Z",
     "iopub.status.idle": "2022-11-03T01:11:31.514193Z",
     "shell.execute_reply": "2022-11-03T01:11:31.513031Z",
     "shell.execute_reply.started": "2022-11-03T01:11:31.507654Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define train and test loaders\n",
    "train_data = TrainReview(X_train,y_train-1)\n",
    "test_data = TestReview(X_test,y_test-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T01:11:31.516739Z",
     "iopub.status.busy": "2022-11-03T01:11:31.515845Z",
     "iopub.status.idle": "2022-11-03T01:11:31.528992Z",
     "shell.execute_reply": "2022-11-03T01:11:31.527788Z",
     "shell.execute_reply.started": "2022-11-03T01:11:31.516697Z"
    }
   },
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 20\n",
    "valid_size = 0.2\n",
    "\n",
    "# get indexes for validation set\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# Sample training set to split into train and validation set\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size,\n",
    "                          sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = DataLoader(train_data, batch_size=batch_size, \n",
    "    sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define FF Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T02:27:10.381511Z",
     "iopub.status.busy": "2022-11-03T02:27:10.381085Z",
     "iopub.status.idle": "2022-11-03T02:27:10.390417Z",
     "shell.execute_reply": "2022-11-03T02:27:10.389301Z",
     "shell.execute_reply.started": "2022-11-03T02:27:10.381478Z"
    }
   },
   "outputs": [],
   "source": [
    "# Construct A Feed-Forward Neural Net\n",
    "# Reference - https://www.kaggle.com/code/mishra1993/pytorch-multi-layer-perceptron-mnist/notebook\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, D_in,D_out):\n",
    "        super(FeedForward, self).__init__()\n",
    "\n",
    "        # Set sizes of hidden layers\n",
    "        hidden_1 = 20\n",
    "        hidden_2 = 20\n",
    "\n",
    "        # Initailize input dimension and output dimension\n",
    "        self.input_size = D_in\n",
    "        self.output_size = D_out\n",
    "\n",
    "        # Construct the Neural net structure\n",
    "        self.fc1 = nn.Linear(self.input_size, hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc3 = nn.Linear(hidden_2, self.output_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add hidden layer 1\n",
    "        x = F.relu(self.fc1(x))\n",
    "#         X = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # add hidden layer 2\n",
    "        x = F.relu(self.fc2(x))\n",
    "#         x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # add output layer\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T02:27:14.044887Z",
     "iopub.status.busy": "2022-11-03T02:27:14.044338Z",
     "iopub.status.idle": "2022-11-03T02:27:14.053846Z",
     "shell.execute_reply": "2022-11-03T02:27:14.052633Z",
     "shell.execute_reply.started": "2022-11-03T02:27:14.044830Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper Functions to check Model Evaluation\n",
    "\n",
    "# Define function to evaluate model\n",
    "def evaluate(model, loader, text = \"Model\"):\n",
    "        \n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    total = 0\n",
    "\n",
    "    # Get data from data loader and get predicted values\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X = X.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(X)\n",
    "\n",
    "            _, predictions = scores.max(1)\n",
    "\n",
    "            # Get the number of correct predictions \n",
    "            correct_predictions += (predictions == y).sum()\n",
    "            total += predictions.size(0)\n",
    "    # Calculate Accuracy\n",
    "    accuracy = float(correct_predictions) / float(total)\n",
    "\n",
    "    return f'{text} gives Accuracy of : {accuracy}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T02:27:16.357555Z",
     "iopub.status.busy": "2022-11-03T02:27:16.356810Z",
     "iopub.status.idle": "2022-11-03T02:27:16.361453Z",
     "shell.execute_reply": "2022-11-03T02:27:16.360713Z",
     "shell.execute_reply.started": "2022-11-03T02:27:16.357518Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T02:31:01.870010Z",
     "iopub.status.busy": "2022-11-03T02:31:01.869637Z",
     "iopub.status.idle": "2022-11-03T02:31:01.878226Z",
     "shell.execute_reply": "2022-11-03T02:31:01.877065Z",
     "shell.execute_reply.started": "2022-11-03T02:31:01.869979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedForward(\n",
      "  (fc1): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Network instance\n",
    "model = FeedForward(20,1)\n",
    "print(model)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.HuberLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T02:31:04.276184Z",
     "iopub.status.busy": "2022-11-03T02:31:04.275801Z",
     "iopub.status.idle": "2022-11-03T02:36:03.654847Z",
     "shell.execute_reply": "2022-11-03T02:36:03.653697Z",
     "shell.execute_reply.started": "2022-11-03T02:31:04.276153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.039122 \tValidation Loss 0.008526\n",
      "Epoch: 2 \tTraining Loss: 0.012910 \tValidation Loss 0.008971\n",
      "Epoch: 3 \tTraining Loss: 0.012298 \tValidation Loss 0.008486\n",
      "Epoch: 4 \tTraining Loss: 0.011807 \tValidation Loss 0.008478\n",
      "Epoch: 5 \tTraining Loss: 0.011672 \tValidation Loss 0.008435\n",
      "Epoch: 6 \tTraining Loss: 0.011384 \tValidation Loss 0.008556\n",
      "Epoch: 7 \tTraining Loss: 0.011194 \tValidation Loss 0.008456\n",
      "Epoch: 8 \tTraining Loss: 0.011017 \tValidation Loss 0.008394\n",
      "Epoch: 9 \tTraining Loss: 0.010831 \tValidation Loss 0.008396\n",
      "Epoch: 10 \tTraining Loss: 0.010635 \tValidation Loss 0.008376\n",
      "Epoch: 11 \tTraining Loss: 0.010577 \tValidation Loss 0.008451\n",
      "Epoch: 12 \tTraining Loss: 0.010489 \tValidation Loss 0.008437\n",
      "Epoch: 13 \tTraining Loss: 0.010386 \tValidation Loss 0.008370\n",
      "Epoch: 14 \tTraining Loss: 0.010411 \tValidation Loss 0.008668\n",
      "Epoch: 15 \tTraining Loss: 0.010298 \tValidation Loss 0.008372\n",
      "Epoch: 16 \tTraining Loss: 0.010270 \tValidation Loss 0.008459\n",
      "Epoch: 17 \tTraining Loss: 0.010198 \tValidation Loss 0.008412\n",
      "Epoch: 18 \tTraining Loss: 0.010180 \tValidation Loss 0.008378\n",
      "Epoch: 19 \tTraining Loss: 0.010102 \tValidation Loss 0.008397\n",
      "Epoch: 20 \tTraining Loss: 0.010071 \tValidation Loss 0.008369\n",
      "Epoch: 21 \tTraining Loss: 0.010078 \tValidation Loss 0.008374\n",
      "Epoch: 22 \tTraining Loss: 0.010069 \tValidation Loss 0.008370\n",
      "Epoch: 23 \tTraining Loss: 0.010156 \tValidation Loss 0.008384\n",
      "Epoch: 24 \tTraining Loss: 0.010038 \tValidation Loss 0.008464\n",
      "Epoch: 25 \tTraining Loss: 0.010079 \tValidation Loss 0.008381\n",
      "Epoch: 26 \tTraining Loss: 0.010002 \tValidation Loss 0.008374\n",
      "Epoch: 27 \tTraining Loss: 0.010006 \tValidation Loss 0.008363\n",
      "Epoch: 28 \tTraining Loss: 0.009964 \tValidation Loss 0.008430\n",
      "Epoch: 29 \tTraining Loss: 0.009975 \tValidation Loss 0.008405\n",
      "Epoch: 30 \tTraining Loss: 0.009976 \tValidation Loss 0.008388\n",
      "Epoch: 31 \tTraining Loss: 0.010009 \tValidation Loss 0.008368\n",
      "Epoch: 32 \tTraining Loss: 0.009931 \tValidation Loss 0.008376\n",
      "Epoch: 33 \tTraining Loss: 0.009939 \tValidation Loss 0.008414\n",
      "Epoch: 34 \tTraining Loss: 0.009988 \tValidation Loss 0.008399\n",
      "Epoch: 35 \tTraining Loss: 0.009922 \tValidation Loss 0.008359\n",
      "Epoch: 36 \tTraining Loss: 0.009826 \tValidation Loss 0.008385\n",
      "Epoch: 37 \tTraining Loss: 0.009926 \tValidation Loss 0.008342\n",
      "Epoch: 38 \tTraining Loss: 0.009910 \tValidation Loss 0.008490\n",
      "Epoch: 39 \tTraining Loss: 0.009825 \tValidation Loss 0.008382\n",
      "Epoch: 40 \tTraining Loss: 0.009909 \tValidation Loss 0.008343\n",
      "Epoch: 41 \tTraining Loss: 0.009827 \tValidation Loss 0.008337\n",
      "Epoch: 42 \tTraining Loss: 0.009878 \tValidation Loss 0.008304\n",
      "Epoch: 43 \tTraining Loss: 0.009787 \tValidation Loss 0.008299\n",
      "Epoch: 44 \tTraining Loss: 0.009831 \tValidation Loss 0.008302\n",
      "Epoch: 45 \tTraining Loss: 0.009824 \tValidation Loss 0.008284\n",
      "Epoch: 46 \tTraining Loss: 0.009717 \tValidation Loss 0.008291\n",
      "Epoch: 47 \tTraining Loss: 0.009708 \tValidation Loss 0.008267\n",
      "Epoch: 48 \tTraining Loss: 0.009708 \tValidation Loss 0.008262\n",
      "Epoch: 49 \tTraining Loss: 0.009702 \tValidation Loss 0.008254\n",
      "Epoch: 50 \tTraining Loss: 0.009693 \tValidation Loss 0.008237\n",
      "Epoch: 51 \tTraining Loss: 0.009647 \tValidation Loss 0.008224\n",
      "Epoch: 52 \tTraining Loss: 0.009641 \tValidation Loss 0.008233\n",
      "Epoch: 53 \tTraining Loss: 0.009654 \tValidation Loss 0.008193\n",
      "Epoch: 54 \tTraining Loss: 0.009569 \tValidation Loss 0.008194\n",
      "Epoch: 55 \tTraining Loss: 0.009531 \tValidation Loss 0.008174\n",
      "Epoch: 56 \tTraining Loss: 0.009600 \tValidation Loss 0.008162\n",
      "Epoch: 57 \tTraining Loss: 0.009518 \tValidation Loss 0.008242\n",
      "Epoch: 58 \tTraining Loss: 0.009552 \tValidation Loss 0.008166\n",
      "Epoch: 59 \tTraining Loss: 0.009458 \tValidation Loss 0.008097\n",
      "Epoch: 60 \tTraining Loss: 0.009455 \tValidation Loss 0.008129\n",
      "Epoch: 61 \tTraining Loss: 0.009406 \tValidation Loss 0.008097\n",
      "Epoch: 62 \tTraining Loss: 0.009418 \tValidation Loss 0.008103\n",
      "Epoch: 63 \tTraining Loss: 0.009325 \tValidation Loss 0.008023\n",
      "Epoch: 64 \tTraining Loss: 0.009346 \tValidation Loss 0.008080\n",
      "Epoch: 65 \tTraining Loss: 0.009393 \tValidation Loss 0.008015\n",
      "Epoch: 66 \tTraining Loss: 0.009303 \tValidation Loss 0.007975\n",
      "Epoch: 67 \tTraining Loss: 0.009338 \tValidation Loss 0.007981\n",
      "Epoch: 68 \tTraining Loss: 0.009336 \tValidation Loss 0.008024\n",
      "Epoch: 69 \tTraining Loss: 0.009191 \tValidation Loss 0.008074\n",
      "Epoch: 70 \tTraining Loss: 0.009229 \tValidation Loss 0.007950\n",
      "Epoch: 71 \tTraining Loss: 0.009216 \tValidation Loss 0.008003\n",
      "Epoch: 72 \tTraining Loss: 0.009134 \tValidation Loss 0.007910\n",
      "Epoch: 73 \tTraining Loss: 0.009074 \tValidation Loss 0.007847\n",
      "Epoch: 74 \tTraining Loss: 0.009059 \tValidation Loss 0.007835\n",
      "Epoch: 75 \tTraining Loss: 0.009065 \tValidation Loss 0.007930\n",
      "Epoch: 76 \tTraining Loss: 0.009011 \tValidation Loss 0.007787\n",
      "Epoch: 77 \tTraining Loss: 0.008977 \tValidation Loss 0.008004\n",
      "Epoch: 78 \tTraining Loss: 0.009024 \tValidation Loss 0.007884\n",
      "Epoch: 79 \tTraining Loss: 0.008906 \tValidation Loss 0.007826\n",
      "Epoch: 80 \tTraining Loss: 0.008876 \tValidation Loss 0.007709\n",
      "Epoch: 81 \tTraining Loss: 0.008843 \tValidation Loss 0.007671\n",
      "Epoch: 82 \tTraining Loss: 0.008831 \tValidation Loss 0.007727\n",
      "Epoch: 83 \tTraining Loss: 0.008804 \tValidation Loss 0.007679\n",
      "Epoch: 84 \tTraining Loss: 0.008807 \tValidation Loss 0.007841\n",
      "Epoch: 85 \tTraining Loss: 0.008792 \tValidation Loss 0.007611\n",
      "Epoch: 86 \tTraining Loss: 0.008809 \tValidation Loss 0.007591\n",
      "Epoch: 87 \tTraining Loss: 0.008704 \tValidation Loss 0.007853\n",
      "Epoch: 88 \tTraining Loss: 0.008737 \tValidation Loss 0.007527\n",
      "Epoch: 89 \tTraining Loss: 0.008735 \tValidation Loss 0.007691\n",
      "Epoch: 90 \tTraining Loss: 0.008696 \tValidation Loss 0.007489\n",
      "Epoch: 91 \tTraining Loss: 0.008768 \tValidation Loss 0.007506\n",
      "Epoch: 92 \tTraining Loss: 0.008628 \tValidation Loss 0.007495\n",
      "Epoch: 93 \tTraining Loss: 0.008615 \tValidation Loss 0.007469\n",
      "Epoch: 94 \tTraining Loss: 0.008614 \tValidation Loss 0.007465\n",
      "Epoch: 95 \tTraining Loss: 0.008695 \tValidation Loss 0.007454\n",
      "Epoch: 96 \tTraining Loss: 0.008678 \tValidation Loss 0.007581\n",
      "Epoch: 97 \tTraining Loss: 0.008588 \tValidation Loss 0.007477\n",
      "Epoch: 98 \tTraining Loss: 0.008598 \tValidation Loss 0.007622\n",
      "Epoch: 99 \tTraining Loss: 0.008518 \tValidation Loss 0.007426\n",
      "Epoch: 100 \tTraining Loss: 0.008577 \tValidation Loss 0.007511\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 100\n",
    "\n",
    "# initialize tracker for minimum validation loss\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    # Prepare model for training\n",
    "    model.train() \n",
    "    for data, target in train_loader:\n",
    "\n",
    "        # Load to device\n",
    "        data,target = data.to(device),target.to(device)\n",
    "        \n",
    "        # Start training the model\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        # Reshape to fit data\n",
    "        output = torch.reshape(output, (output.size()[0],))\n",
    "        \n",
    "        # calculate loss function and perform back propogation\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "\n",
    "    # Perform validation\n",
    "    model.eval() \n",
    "    for data, target in valid_loader:\n",
    "        \n",
    "        # Load to device\n",
    "        data,target = data.to(device),target.to(device)\n",
    "        output = model(data)\n",
    "        \n",
    "        # Reshape to fit data\n",
    "        output = torch.reshape(output, (output.size()[0],))\n",
    "        \n",
    "        # Calculate loss function\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # update running validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        \n",
    "\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1} \\tTraining Loss: {train_loss / len(train_loader):.6f} \\tValidation Loss {valid_loss / len(valid_loader):.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T02:36:03.657119Z",
     "iopub.status.busy": "2022-11-03T02:36:03.656624Z",
     "iopub.status.idle": "2022-11-03T02:36:03.664442Z",
     "shell.execute_reply": "2022-11-03T02:36:03.663466Z",
     "shell.execute_reply.started": "2022-11-03T02:36:03.657086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([46.8605, 46.2019, 49.1326, 46.0305, 48.2928, 46.0495, 46.0020, 46.0012,\n",
      "        46.0196], grad_fn=<ReshapeAliasBackward0>) tensor([32.8000, 36.6000, 48.3000, 37.7000, 40.0000, 47.2000, 47.9000, 56.2000,\n",
      "        49.2000])\n"
     ]
    }
   ],
   "source": [
    "print(output,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-03T02:36:03.666504Z",
     "iopub.status.busy": "2022-11-03T02:36:03.665777Z",
     "iopub.status.idle": "2022-11-03T02:36:05.799839Z",
     "shell.execute_reply": "2022-11-03T02:36:05.798706Z",
     "shell.execute_reply.started": "2022-11-03T02:36:03.666464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed Forward Network gives Accuracy of : 0.298765\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, train_loader,\"Feed Forward Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Protien Similarities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
